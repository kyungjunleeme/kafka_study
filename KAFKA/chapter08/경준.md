# 카프카에서 '정확히 한 번' 메시지 전달을 구현하기 위한 방법

## 멱등적 프로듀서

멱등적 프로듀서는 동일한 메시지가 중복 처리되는 것을 방지합니다.

### 작동 원리
- 각 메시지에 고유한 프로듀서 ID와 시퀀스 넘버를 부여하여 중복을 탐지합니다.
- 브로커는 각 파티션별로 최근 5개의 메시지를 추적하여 중복 여부를 확인합니다.
- 프로듀서 재시작 시 새로운 프로듀서 ID가 할당되어 이전 상태와 구분됩니다.
- 브로커 장애 시에도 인메모리 상태가 복제되어 중복 방지가 유지됩니다.

### 한계
- 프로듀서 내부 로직에 의한 재시도에만 중복 방지가 적용됩니다.
- 동일한 메시지를 수동으로 두 번 전송하는 경우에는 중복이 발생할 수 있습니다.

### 사용법
- 프로듀서 설정에서 `enable.idempotence=true`로 설정합니다.
- `acks=all` 설정 시 성능 저하 없이 사용할 수 있습니다.

---

## 트랜잭션

트랜잭션은 읽기-처리-쓰기 패턴에서 '정확히 한 번' 처리를 보장합니다.

### 해결하는 문제
1. 레코드 처리 후 오프셋 커밋 전에 크래시가 발생하여 중복 처리가 되는 문제.
2. 레코드 읽기 직후 크래시 발생 시 다른 컨슈머에 의한 중복 처리 문제.

### 작동 방식
1. **원자적 다수 파티션 쓰기**
   - 트랜잭션적 프로듀서를 통해 여러 파티션에 대한 쓰기를 원자적으로 수행합니다.
   - `transactional.id`를 설정하여 프로듀서 재시작 시에도 동일한 ID를 사용합니다.
2. **좀비 펜싱**
   - 재시작된 프로듀서의 이전 인스턴스(좀비)가 쓰기를 수행하지 못하도록 에포크 방식을 사용하여 차단합니다.
3. **컨슈머 격리 수준**
   - `isolation.level=read_committed`로 설정하여 커밋된 메시지만 읽도록 합니다.

### 한계
1. 스트림 처리 중 외부 시스템과의 상호작용에서 발생하는 부작용.
2. 카프카에서 데이터베이스로의 데이터 저장 시 원자적 처리가 어려운 경우.
3. 클러스터 간 데이터 복제 시 트랜잭션 정보가 전달되지 않는 문제.
4. 발행/구독 패턴에서 중복 처리를 완전히 방지하지 못하는 경우.

### 사용법
- 카프카 스트림즈 애플리케이션에서는 `processing.guarantee=exactly_once`로 설정하여 자동으로 트랜잭션을 관리합니다.
- 직접 트랜잭션 API를 사용할 경우, `KafkaProducer`의 `beginTransaction`, `commitTransaction` 메서드를 활용합니다.
- 프로듀서에 `transactional.id`를 설정하고, `initTransactions()`를 호출한 후, `sendOffsetsToTransaction` 메서드로 오프셋을 커밋하여 원자적 처리를 구현합니다.

---

위의 방법들을 활용하여 카프카에서 '정확히 한 번' 메시지 전달을 구현할 수 있습니다.
