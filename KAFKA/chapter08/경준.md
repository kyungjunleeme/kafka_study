# 카프카에서 '정확히 한 번' 메시지 전달을 구현하기 위한 방법

## 멱등적 프로듀서

멱등적 프로듀서는 동일한 메시지가 중복 처리되는 것을 방지합니다.

### 작동 원리
- 각 메시지에 고유한 프로듀서 ID와 시퀀스 넘버를 부여하여 중복을 탐지합니다.
- 브로커는 각 파티션별로 최근 5개의 메시지를 추적하여 중복 여부를 확인합니다.
- 프로듀서 재시작 시 새로운 프로듀서 ID가 할당되어 이전 상태와 구분됩니다.
- 브로커 장애 시에도 인메모리 상태가 복제되어 중복 방지가 유지됩니다.

### 한계
- 프로듀서 내부 로직에 의한 재시도에만 중복 방지가 적용됩니다.
- 동일한 메시지를 수동으로 두 번 전송하는 경우에는 중복이 발생할 수 있습니다.

### 사용법
- 프로듀서 설정에서 `enable.idempotence=true`로 설정합니다.
- `acks=all` 설정 시 성능 저하 없이 사용할 수 있습니다.

---

## 트랜잭션

트랜잭션은 읽기-처리-쓰기 패턴에서 '정확히 한 번' 처리를 보장합니다.

### 해결하는 문제
1. 레코드 처리 후 오프셋 커밋 전에 크래시가 발생하여 중복 처리가 되는 문제.
2. 레코드 읽기 직후 크래시 발생 시 다른 컨슈머에 의한 중복 처리 문제.

### 작동 방식
1. **원자적 다수 파티션 쓰기**
   - 트랜잭션적 프로듀서를 통해 여러 파티션에 대한 쓰기를 원자적으로 수행합니다.
   - `transactional.id`를 설정하여 프로듀서 재시작 시에도 동일한 ID를 사용합니다.
2. **좀비 펜싱**
   - 재시작된 프로듀서의 이전 인스턴스(좀비)가 쓰기를 수행하지 못하도록 에포크 방식을 사용하여 차단합니다.
3. **컨슈머 격리 수준**
   - `isolation.level=read_committed`로 설정하여 커밋된 메시지만 읽도록 합니다.

### 한계
1. 스트림 처리 중 외부 시스템과의 상호작용에서 발생하는 부작용.
2. 카프카에서 데이터베이스로의 데이터 저장 시 원자적 처리가 어려운 경우.
3. 클러스터 간 데이터 복제 시 트랜잭션 정보가 전달되지 않는 문제.
4. 발행/구독 패턴에서 중복 처리를 완전히 방지하지 못하는 경우.

### 사용법
- 카프카 스트림즈 애플리케이션에서는 `processing.guarantee=exactly_once`로 설정하여 자동으로 트랜잭션을 관리합니다.
- 직접 트랜잭션 API를 사용할 경우, `KafkaProducer`의 `beginTransaction`, `commitTransaction` 메서드를 활용합니다.
- 프로듀서에 `transactional.id`를 설정하고, `initTransactions()`를 호출한 후, `sendOffsetsToTransaction` 메서드로 오프셋을 커밋하여 원자적 처리를 구현합니다.

---

위의 방법들을 활용하여 카프카에서 '정확히 한 번' 메시지 전달을 구현할 수 있습니다.


25.01.20
- 경준 다시 정리중
https://rudaks.tistory.com/entry/spring-kafka%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%A0-%EB%95%8C%EC%9D%98-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98-%EC%B2%98%EB%A6%AC
여기 나온 내용 다시 살펴 볼 것

- https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html
- https://westlife0615.tistory.com/607
- https://github.com/confluentinc/librdkafka/issues/2414
- https://www.confluent.io/blog/debug-apache-kafka-reduced-message-throughput/
- https://www.confluent.io/blog/5-common-pitfalls-when-using-apache-kafka/
- https://www.confluent.io/blog/streaming-etl-with-confluent-kafka-message-routing-and-fan-out/
- https://www.confluent.io/blog/kafka-python-asyncio-integration/



성택님 보충 내용

- EventLoop는 운영체제에 따라 NIO, Epoll, KQueue 등 여러 방식을 지원
- https://chatgpt.com/share/678f4a34-1d5c-8009-9756-9fb5831466ad
- https://www.confluent.io/blog/streaming-etl-with-confluent-kafka-message-routing-and-fan-out/


https://jun10920.tistory.com/48
https://imksh.com/129
https://www.confluent.io/blog/debug-apache-kafka-reduced-message-throughput/
https://jsyeo.tistory.com/entry/%EC%98%AC%EB%A6%AC%EB%B8%8C%EC%98%81-%EC%98%A8%EB%9D%BC%EC%9D%B8-%EC%87%BC%ED%95%91%EB%AA%B0-public-cloudAWS-%EC%9D%B8%ED%94%84%EB%9D%BC-%EA%B5%AC%EC%B6%95-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8?category=1217581


p.207(한국책) <> p.183(원서)
```markdown
What if a broker receives a sequence number that is unexpectedly high? The broker
expects message number 2 to be followed by message number 3; what happens if the
broker receives message number 27 instead? In such cases the broker will respond
with an “out of order sequence” error, but if we use an idempotent producer without
using transactions, this error can be ignored.
While the producer will continue normally after encountering an
“out of order sequence number” exception, this error typically indi‐
cates that messages were lost between the producer and the
broker—if the broker received message number 2 followed by mes‐
sage number 27, something must have happened to messages 3 to
26. When encountering such an error in the logs, it is worth revisit‐
ing the producer and topic configuration and making sure the pro‐
ducer is configured with recommended values for high reliability
and to check whether unclean leader election has occurred.
As is always the case with distributed systems, it is interesting to consider the behav‐
ior of an idempotent producer under failure conditions. Consider two cases: pro‐
ducer restart and broker failure.
```
-> 

```java
     } else if (error == Errors.OUT_OF_ORDER_SEQUENCE_NUMBER) {
         if (!hasUnresolvedSequence(batch.topicPartition) &&
                 (batch.sequenceHasBeenReset() || !isNextSequence(batch.topicPartition, batch.baseSequence()))) {
             // We should retry the OutOfOrderSequenceException if the batch is _not_ the next batch, ie. its base
             // sequence isn't the lastAckedSequence + 1.
             return true;
         } else if (!isTransactional()) {
             // For the idempotent producer, retry all OUT_OF_ORDER_SEQUENCE_NUMBER errors. If there are no
             // unresolved sequences, or this batch is the one immediately following an unresolved sequence, we know
             // there is actually a gap in the sequences, and we bump the epoch. Otherwise, retry without bumping
             // and wait to see if the sequence resolves
             if (!hasUnresolvedSequence(batch.topicPartition) ||
                     isNextSequenceForUnresolvedPartition(batch.topicPartition, batch.baseSequence())) {
                 requestIdempotentEpochBumpForPartition(batch.topicPartition);
             }
             return true;
         }
     }
```


```java
    synchronized TransactionalRequestResult initializeTransactions(ProducerIdAndEpoch producerIdAndEpoch) {
        maybeFailWithError();

        boolean isEpochBump = producerIdAndEpoch != ProducerIdAndEpoch.NONE;
        return handleCachedTransactionRequestResult(() -> {
            // If this is an epoch bump, we will transition the state as part of handling the EndTxnRequest
            if (!isEpochBump) {
                transitionTo(State.INITIALIZING);
                log.info("Invoking InitProducerId for the first time in order to acquire a producer ID");
            } else {
                log.info("Invoking InitProducerId with current producer ID and epoch {} in order to bump the epoch", producerIdAndEpoch);
            }
            InitProducerIdRequestData requestData = new InitProducerIdRequestData()
                    .setTransactionalId(transactionalId)
                    .setTransactionTimeoutMs(transactionTimeoutMs)
                    .setProducerId(producerIdAndEpoch.producerId)
                    .setProducerEpoch(producerIdAndEpoch.epoch);
            InitProducerIdHandler handler = new InitProducerIdHandler(new InitProducerIdRequest.Builder(requestData),
                    isEpochBump);
            enqueueRequest(handler);
            return handler.result;
        }, State.INITIALIZING, "initTransactions");
    }
```

```markdown
Producer ID가 없는 경우 (isEpochBump == false)

새로운 Producer ID를 요청 (InitProducerId 요청).
프로듀서 상태를 INITIALIZING으로 변경.
이미 Producer ID가 있는 경우 (isEpochBump == true)

Epoch만 증가시키는 요청을 보냄.
트랜잭션이 종료될 때마다 Epoch을 증가시켜 중복 방지.
```

208-복구과정
209-



p.221 -> 

Preventing zombie instances of the application from creating duplicates requires a
mechanism for zombie fencing, or preventing zombie instances of the application
from writing results to the output stream. The usual way of fencing zombies—using
an epoch—is used here. Kafka increments the epoch number associated with a
transactional.id when initTransaction() is invoked to initialize a transactional
producer. Send, commit, and abort requests from producers with the same
transactional.id but lower epochs will be rejected with the FencedProducer error.
The older producer will not be able to write to the output stream and will be forced to
close(), preventing the zombie from introducing duplicate records. In Apache Kafka
2.5 and later, there is also an option to add consumer group metadata to the transac‐
tion metadata. This metadata will also be used for fencing, which will allow producers
with different transactional IDs to write to the same partitions while still fencing
against zombie instances?  ㅌ  .

왜 이런게 필요해 ? 이미 다른걸  -> 세종님 질문



LSO(Last Stable Offset)
Figure 8-2. Consumers in read_committed mode will lag behind consumers with default
configuration


isoloation_level 설정 -> Consumer 설정
- https://rudaks.tistory.com/entry/spring-kafka%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%A0-%EB%95%8C%EC%9D%98-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98-%EC%B2%98%EB%A6%AC
- 

카프카를 공부하기에 어려운 점
- 설정이 어떤 설정에 적용해야하는 지 헷갈린다.  # 종웅님이랑 찾아본거 있음



Our simple stream processing job will have exactly-once guarantees on its output
even if the input was written nontransactionally. The atomic multipartition produce
guarantees that if the output records were committed to the output topic, the offset of
the input records was also committed for that consumer, and as a result the input
records will not be processed again.


An important pattern to avoid is publishing a message and then
waiting for another application to respond before committing the
transaction. The other application will not receive the message
until after the transaction was committed, resulting in a deadlock.

https://firststep-de.tistory.com/41

참고해서 같이 읽기



consumer group 세대
https://cwiki.apache.org/confluence/display/KAFKA/KIP-848%3A+The+Next+Generation+of+the+Consumer+Rebalance+Protocol


```markdown
🔎 Kafka의 Consumer Group과 Partition Assignment 문제
🔥 Kafka Consumer Group의 기본 동작
Kafka의 **컨슈머 그룹(Consumer Group)**에서는 여러 개의 컨슈머가 동일한 토픽의 파티션을 나눠서 읽음.
컨슈머 그룹에서 컨슈머가 추가되거나 제거될 때, Kafka는 자동으로 **리밸런스(rebalance)**를 수행하여 파티션을 재할당합니다.
❌ Rebalance로 인해 발생하는 문제
기존에 파티션 0을 읽던 컨슈머가 리밸런스로 인해 다른 컨슈머에게 할당되면?
같은 키를 가진 데이터가 다른 파티션으로 전송될 가능성이 생김.
이렇게 되면 Kafka Streams에서 State Store의 정합성이 깨질 수 있음.


```

https://easywritten.com/post/kafka-message-delivery-semantics/

# EOS 구현
https://github.com/confluentinc/confluent-kafka-python/blob/master/examples/eos-transactions.py



# 이 사람이 정리를 제일 잘함
https://whitepro.tistory.com/1039
https://developer.confluent.io/courses/architecture/transactions/
https://easywritten.com/post/kafka-message-delivery-semantics/
