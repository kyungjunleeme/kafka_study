## chapter 08 정확히 한 번 의미 구조
- **멱등적 프로듀서**
  - 프로듀서 재시도로 인한 중복 방지
- **트랜잭션 의미구조**
  - 정확한 한 번의 처리를 보장
---
### 멱등적 프로듀서
- **멱등적** 이란?
  - 동일한 작업을 여러 번 실행해도 한 번 실행한 결과처럼 보장 하는 것

### 멱등적 프로듀서의 작동 원리
- `enable.idempotence=true`
```
멱등적 프로듀서 기능을 켜면 모든 메세지는 고유한 프로듀서 ID 와 시퀀스 넘버를 가지게 된다.
PID 와 Sequence ID 조합으로 고유한 메세지를 판별
```
- 파티션별 추적 시퀀스 넘버의 수을 제한하고 싶을 때
  - `max.in.flights.requests.per.connection` (기본값 : 5)
- 브로커가 예상보다 높은 Sequence ID 를 수신하면 어떻게 될까?
  - `out of orderd sequence number` 에러 발생
  - 프로듀서와 브로커 사이에 메세지 유실이 있었음을 의미
  - 트랜젝션 기능 없이 사용하고 있다면 큰 문제는 아님

### 프로듀서 재시작
- 장애 시 복구절차로 보통은 새 프로듀서를 생성하여 장애 프로듀서를 대체함
```
멱등적 프로듀서 기능이 켜졌을 경우 새로운 PID 를 생성
멱등적 프로듀서 기능이 켜지고 트랜잭션 기능을 키지 않았을 때, 완전히 새로운 PID 로 생성되며
기존 프로듀서 측 전송된 메세지가 있을 경우 
새로운 프로듀서는 해당 메세지가 중복인지 판별할 수 없다.
```
- 멱등적 프로듀서 O + 트랜잭션 X 일 때, 기존 프로듀서를 재실행하면 어떻게 될까?
  - 서로 다른 PID 를 가지고 있어 기존 프로듀서는 좀비로 취급되지 않으며, 재시도에 의해 처리된 만큼 메세지 중복을 야기 할 수 있다.

### 브로커 장애
- 리더는 메세지가 쓰여질 때 인-메모리에 최근 5개의 시퀀스 넘버를 업데이트
- 팔로워는 새로운 메세지를 복제 할 때 마다 시퀀스 넘버도 업데이트
- 새 리더가 선출되고 기존 리더가 복구되면 어떻게 될까?
  - 클러스터 내 컨트롤러에 의해 재차 리더로 선출되며, 컨트롤러는 재차 메타데이터를 브로드캐스트를 한다.
  - 브로커는 종료되거나 새 세그먼트가 생성될 때 마다 프로듀서 상태를 스냅샷 형태로 저장
  - PID,Sequence ID 는 메세지 형태의 로그이며 이 또한 스냅샷 형태에 저장됨
  - 새로 선출된 리더는 각 파티션 최신 세그먼트의 메세지 또한 복구함

### 멱등적 프로듀서의 한계
- 프로듀서의 내부 로직에서 재시도가 일어났을 때만 방어함
- 다중 어플리케이션에서 메세지를 중복으로 보냈을 경우엔 중복으로 인지하지 못함

### 멱등적 프로듀서 설정 시 변경점
- `acks = 'all'` 이 되어 있다면 `enable.idempotence = true` 설정을 주어도 비용이 없다. (왜?)
1. PID 를 가져오기 위한 API 호출
2. 레코드 배치에서 PID와 첫 메세지에 Sequence ID 포함 (PID : long, Seqence ID : int)
3. 브로커는 레코드 배치의 Sequence ID 로 중복 검사
4. 2.5 (KIP-360) 이후 기본 값으로 에러가 발생할 경우 모든 전송중인 레코드 배치를 거부함 (메세지 순서 보장)

## 트랜잭션

### 트랜잭션 의미구조를 보장하지 않았을 때 문제점
### 트랜잭션이 해결하는 문제
- 애플리케이션 크래시로 인한 재처리
  - 메세지는 출력 토픽에 쓰여짐, 메세지의 오프셋을 커밋
  - 오프셋이 커밋되기전 크래시가 날 경우
    - 새로 할당된 파티션의 마지막 오프셋의 레코드를 읽어옴
```
예를 들어 0-10, 10-20 중 출력 토픽은 0-20 까지 쓰여졌고
오프셋은 0-10 까지 커밋하고 크래시가 났으면
어플리케이션에 의해 재수행은 10-20 이 출력 토픽을 쓰는 단계부터 진행하게 된다.
이에따라 10-20 은 중복 메세지가 발생함
```
### 좀비 애플리케이션에 의해 발생하는 재처리
- 하트비트를 통한 헬스 체크로 어플리케이션이 죽고 컨슈머 그룹에서 새로운 컨슈머가 할당됨
- 기존 어플리케이션 재동작
- 메티데이터를 재풀링 하거나 하트비트를 통한 어플리케이션 헬스체크가 진행되기 전까지 기존 어플리케이션은 메세지 중복 소비 할 수 있다.

### 카프카가 트랜잭션을 보장하는 방식
- 원자성을 보장하는 방식
- 카프카는 atomic multipartition write 기능을 도입
- 결과는 출력 토픽, 오프셋은 _consumer_offsets 토픽에 쓰여짐
- `transactional.id`는 `product.id`와 같은 식별자가 아닌 설정에 키로 활용하는 것으로 이해
- 카프카는 `transactional.id` 와 `producer.id`로 키밸류 관계를 유지
- 이미 있는 `transactional.id` 프로듀서가 `initTransactions()` 메서드를 호출하면 이전에 쓰던 `producer_id`를 밸류로 할당 한다.

### 좀비 펜싱
- `initTransactions()`를 호출하면 `transactional.id` 에 `epoch` 밸류가 증가
- 동일한 `transactional.id` 를 가지고 있는 프로듀서 중 `epoch`가 낮은 프로듀서는 `FencedProducder` 에러를 반환하며 좀비 펜싱
- 2.5 버전 이후 부터는 트랜젝션 메타데이터에 컨슈머 그룹 메타데이터를 추가 할 수 있는 옵션이 생김
- 즉 쓰기에서는 중복을 허용할 수 있으며, 읽기에서 중복 방지를 보장할 수 있게끔 한다.

### 격리수준

| **Isolation Level** | **설명**                                                                                             | **프로듀서 동작**                                       | **컨슈머 동작**                                   |
|--------------------------------|---------------------------------------------------------------------------------------------------|-------------------------------------------------------|-------------------------------------------------|
| `read_uncommitted`             | 트랜잭션이 완료되지 않은 메시지도 읽을 수 있음.                                                    | 트랜잭션이 완료되지 않은 메시지도 전송 가능.           | 트랜잭션이 완료되지 않은 메시지도 소비 가능.     |
| `read_committed`               | 완료된 트랜잭션의 메시지만 소비됨. 미완료된 메시지는 소비되지 않음.                                    | 트랜잭션이 완료된 메시지만 전송.                       | 트랜잭션이 완료된 메시지만 소비.                 |

### 스트림 처리 원자성 보장 방식
- read_uncommitted
  - 출력 토픽에 커밋이 되면, _consumer_offsets 토픽에도 커밋이 됨으로써 `transactional.id` 에 컨슈머그룹, 프로듀서Id 가 할당되지 않아도 입력 레코드 재처리 방지를 보장한다.

## 트랜잭션으로 해결할 수 없는 문제들
- 트랜잭션 기능은 원자적 쓰기, 좀비 프로듀서 방지를 위해 추가됨
- 작성된 글에서 `즉 쓰기에서는 중복을 허용할 수 있으며, 읽기에서 중복 방지를 보장할 수 있게끔 한다.`
- 이는 읽기-처리-쓰기 전체의 프로세스에서 원자성을 보장한다는 뜻이며 개별로써 읽기의 원자성을 보장한다는 것은 아님
- 즉 쓰기에선 `transactional.id` 가 발생하지만, 읽기에선 `transactional.id`가 발생하지 않음

---
## 장애상황 테스트

---

### 장애상황 : 브로커 부하 발생 (CPU, VM)

### 환경
- 카프카 브로커 3대 (29092, 29093, 29094)
- Crawling Server (프로듀서, 컨슈머 역할 수행)

### 시나리오
1. CPU 코어 부하 테스트
2. VM 부하 테스트

---
### CPU (1/2 코어) 기대 결과값
- 전송처리 속도 저하 (속도 측정)

### 테스트 사전 준비
- 도커파일 작성 시 EPEL 저장소 설치
- 이미지별 OS 를 확인하여 설치 (아카이브 경로 : `https://archives.fedoraproject.org/pub/archive/epel/`)
- `yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm`
- root 사용자로 컨테이너를 실행하여 권한 문제 해결
- 브로커 다운 시 disaster recovery 목적의 `KAFKA_MIN_INSYNC_REPLICAS: 2` 설정

### CPU 부하 테스트 브로커 설정
```yaml
  kafka1:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka1
    container_name: kafka1
    user: root
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_MIN_INSYNC_REPLICAS: 2
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    command: >
      bash -c "
      yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm && 
      yum install -y stress &&
      /etc/confluent/docker/run
      "
```
---
- `docker compose -f {yaml} up -d`  전체 환경 실행
- `docker exec -it --user=root {ContainerId} /bin/bash` 를 통해 root 유저로 쉘 접근
-  컨테이너 할당 리소스 `top`
- `kafka-producer-perf-test`를 통한 퍼포먼스 측정 `cpu 부하 상황 vs 평시`
- `kafka-topics --create --topic cpu0 --bootstrap-server {localhost:}` 토픽 생성
![create](https://github.com/user-attachments/assets/250de85e-6bac-4f9f-ae07-4792d9ea5475)
- 카프카 부하 테스트를 위한 쉘스크립트 `kafka-producer-perf-test` 사용
```
kafka-producer-perf-test \
--producer-props bootstrap.servers={브로커} \
--topic {토픽} \
--num-records {레코드 개수} \
--throughput {처리량} \
--record-size {레코드 사이즈} \
--print-metric
```
### 평시 상황 테스트
![resource_0](https://github.com/user-attachments/assets/a3b17e72-b85c-4e8a-b922-b82b24076cb0)
```
평시상황 평가 결과
[root@kafka1 appuser]# kafka-producer-perf-test --producer-props bootstrap.servers=localhost:29092 --topic cpu0 --num-records 500 --throughput 10 --record-size 1024 --print-metric
51 records sent, 10.2 records/sec (0.01 MB/sec), 42.0 ms avg latency, 612.0 ms max latency.
51 records sent, 10.1 records/sec (0.01 MB/sec), 11.8 ms avg latency, 24.0 ms max latency.
51 records sent, 10.1 records/sec (0.01 MB/sec), 11.6 ms avg latency, 15.0 ms max latency.
51 records sent, 10.0 records/sec (0.01 MB/sec), 11.2 ms avg latency, 14.0 ms max latency.
50 records sent, 9.9 records/sec (0.01 MB/sec), 10.9 ms avg latency, 13.0 ms max latency.
51 records sent, 10.1 records/sec (0.01 MB/sec), 10.7 ms avg latency, 15.0 ms max latency.
51 records sent, 10.1 records/sec (0.01 MB/sec), 10.7 ms avg latency, 30.0 ms max latency.
50 records sent, 9.8 records/sec (0.01 MB/sec), 10.5 ms avg latency, 17.0 ms max latency.
51 records sent, 10.0 records/sec (0.01 MB/sec), 9.9 ms avg latency, 13.0 ms max latency.
500 records sent, 10.016026 records/sec (0.01 MB/sec), 14.03 ms avg latency, 612.00 ms max latency, 11 ms 50th, 14 ms 95th, 182 ms 99th, 612 ms 99.9th.
```
### CPU 부하 상황 테스트
- `stress --cpu 1` 부하를 주어 동일한 테스트 진행

![resource_1](https://github.com/user-attachments/assets/d884ece5-2045-43dc-b5a1-c56d59d97cf3)
```
부하상황 평가 결과
  [root@kafka1 appuser]# kafka-producer-perf-test --producer-props bootstrap.servers=localhost:29092 --topic cpu0 --num-records 500 --throughput 10 --record-size 1024 --print-metric
52 records sent, 10.3 records/sec (0.01 MB/sec), 22.4 ms avg latency, 561.0 ms max latency.
50 records sent, 9.9 records/sec (0.01 MB/sec), 6.6 ms avg latency, 18.0 ms max latency.
51 records sent, 10.1 records/sec (0.01 MB/sec), 6.1 ms avg latency, 11.0 ms max latency.
50 records sent, 10.0 records/sec (0.01 MB/sec), 5.7 ms avg latency, 16.0 ms max latency.
50 records sent, 9.9 records/sec (0.01 MB/sec), 5.7 ms avg latency, 13.0 ms max latency.
51 records sent, 10.2 records/sec (0.01 MB/sec), 5.9 ms avg latency, 15.0 ms max latency.
50 records sent, 9.9 records/sec (0.01 MB/sec), 5.1 ms avg latency, 21.0 ms max latency.
50 records sent, 9.9 records/sec (0.01 MB/sec), 5.7 ms avg latency, 16.0 ms max latency.
51 records sent, 10.1 records/sec (0.01 MB/sec), 5.3 ms avg latency, 16.0 ms max latency.
500 records sent, 10.016226 records/sec (0.01 MB/sec), 7.43 ms avg latency, 561.00 ms max latency, 5 ms 50th, 12 ms 95th, 49 ms 99th, 561 ms 99.9th.
```

| Metric Name                                                                                 | 평시 상황                                    | 부하 상황                                    |
|---------------------------------------------------------------------------------------------|------------------------------------------|------------------------------------------|
| app-info:commit-id                                                                          | 853191ff421b2935dfa531545651ab667b809801 | 853191ff421b2935dfa531545651ab667b809801 |
| app-info:start-time-ms                                                                      | 1736510326135                            | 1736510519168                            |
| app-info:version                                                                            | 7.3.2-ccs                                | 7.3.2-ccs                                |
| kafka-metrics-count                                                                         | 112.000                                  | 112.000                                  |
| producer-metrics:batch-size-avg                                                             | 1141.544                                 | 1134.817                                 |
| producer-metrics:batch-size-max                                                             | 6259.000                                 | 7298.000                                 |
| producer-metrics:batch-split-rate                                                           | 0.000                                    | 0.000                                    |
| producer-metrics:batch-split-total                                                          | 0.000                                    | 0.000                                    |
| producer-metrics:buffer-available-bytes                                                    | 33554432.000                             | 33554432.000                             |
| producer-metrics:compression-rate-avg                                                       | 1.000                                    | 1.000                                    |
| producer-metrics:connection-count                                                           | 2.000                                    | 2.000                                    |
| producer-metrics:flush-time-ns-total                                                        | 1231513.000                              | 496939.000                               |
| producer-metrics:incoming-byte-rate                                                         | 551.759                                  | 555.341                                  |
| producer-metrics:io-time-ns-avg                                                             | 269153.946                               | 188247.852                               |
| producer-metrics:io-wait-time-ns-avg                                                        | 33297709.189                             | 33339030.180                             |
| producer-metrics:io-wait-time-ns-total                                                      | 48115189778.000                          | 48474949881.000                          |
| producer-metrics:metadata-age                                                               | 49.558                                   | 49.504                                   |
| producer-metrics:outgoing-byte-rate                                                         | 11555.408                                | 11569.479                                |
| producer-metrics:record-queue-time-avg                                                      | 0.822                                    | 0.401                                    |
| producer-metrics:record-send-rate                                                           | 10.109                                   | 10.125                                   |
| producer-metrics:request-latency-avg                                                        | 9.891                                    | 5.141                                    |
| producer-metrics:request-latency-max                                                        | 110.000                                  | 20.000                                   |
| producer-metrics:request-size-avg                                                           | 1190.087                                 | 1183.474                                 |
| producer-metrics:request-size-max                                                           | 6317.000                                 | 7298.000                                 |
| producer-metrics:request-total                                                              | 482.000                                  | 488.000                                  |
| producer-metrics:response-total                                                             | 482.000                                  | 488.000                                  |
| producer-topic-metrics:byte-rate:{topic=cpu0}                                               | 11034.540                                | 11045.321                                |
| producer-topic-metrics:record-send-rate:{topic=cpu0}                                        | 10.111                                   | 10.125                                   |

- 오히려 부하 상황일 때 레이턴시 외 IO 성능이 증가함을 볼 수 있다
- 레코드 사이즈 1024byte 에서 4096byte 로 증가 레코드 숫자를 300으로 낮추어 재진행
- `kafka-producer-perf-test --producer-props bootstrap.servers=localhost:29092 --topic cpu0 --num-records 300 --throughput 10 --record-size 4096 --print-metric`

  | **항목**                | **평시 상황**                           | **부하 상황**                           |
  |-------------------------|-------------------------------------|-------------------------------------|
  | **총 전송 레코드 수**   | 300 records sent                    | 300 records sent                    |
  | **평균 처리량**         | 10.024058 records/sec (0.04 MB/sec) | 10.027408 records/sec (0.04 MB/sec) |
  | **평균 대기 시간**      | 13.06 ms                            | 12.31 ms                            |
  | **최대 대기 시간**      | 492.00 ms                           | 1018.00 ms                          |
  | **50th Percentile**     | 11 ms                               | 5 ms                                |
  | **95th Percentile**     | 13 ms                               | 13 ms                               |
  | **99th Percentile**     | 61 ms                               | 94 ms                               |
  | **99.9th Percentile**   | 492 ms                              | 1018 ms                             |

- 사이즈가 커졌음에도 평균 처리 속도는 달라지지 않았고, 처리대기 없이 많은 토픽을 주게 되어야 차이가 나는지 확인 해보겠다.

### 인터벌 시간을 축소 레코드 숫자 증가
- `kafka-producer-perf-test --producer-props bootstrap.servers=localhost:29092 --topic cpu0 --num-records 1000000 --throughput -1 --record-size 1024 --print-metric`

```
[root@kafka1 appuser]# kafka-producer-perf-test --producer-props bootstrap.servers=localhost:29092 --topic cpu0 --num-records 1000000 --throughput -1 --record-size 1024 --print-metric
18916 records sent, 3782.4 records/sec (3.69 MB/sec), 1896.5 ms avg latency, 3118.0 ms max latency.
25170 records sent, 5032.0 records/sec (4.91 MB/sec), 4809.7 ms avg latency, 5965.0 ms max latency.
24660 records sent, 4931.0 records/sec (4.82 MB/sec), 6147.5 ms avg latency, 6336.0 ms max latency.
32745 records sent, 6547.7 records/sec (6.39 MB/sec), 5405.2 ms avg latency, 6169.0 ms max latency.
32400 records sent, 6477.4 records/sec (6.33 MB/sec), 4603.2 ms avg latency, 4771.0 ms max latency.
37110 records sent, 7420.5 records/sec (7.25 MB/sec), 4535.8 ms avg latency, 4833.0 ms max latency.
33390 records sent, 6675.3 records/sec (6.52 MB/sec), 4636.3 ms avg latency, 4867.0 ms max latency.
34530 records sent, 6903.2 records/sec (6.74 MB/sec), 4214.1 ms avg latency, 4561.0 ms max latency.
40890 records sent, 8174.7 records/sec (7.98 MB/sec), 3949.8 ms avg latency, 4579.0 ms max latency.
42660 records sent, 8525.2 records/sec (8.33 MB/sec), 3608.1 ms avg latency, 3931.0 ms max latency.
9975 records sent, 1974.1 records/sec (1.93 MB/sec), 5138.6 ms avg latency, 7746.0 ms max latency.
44085 records sent, 8815.2 records/sec (8.61 MB/sec), 6128.3 ms avg latency, 8026.0 ms max latency.
8820 records sent, 1758.7 records/sec (1.72 MB/sec), 5073.2 ms avg latency, 7493.0 ms max latency.
5805 records sent, 1160.8 records/sec (1.13 MB/sec), 11138.9 ms avg latency, 12232.0 ms max latency.
21570 records sent, 4293.4 records/sec (4.19 MB/sec), 13489.2 ms avg latency, 14165.0 ms max latency.
3420 records sent, 683.0 records/sec (0.67 MB/sec), 13719.7 ms avg latency, 15461.0 ms max latency.
3975 records sent, 790.6 records/sec (0.77 MB/sec), 14472.2 ms avg latency, 15462.0 ms max latency.
2400 records sent, 476.9 records/sec (0.47 MB/sec), 17554.0 ms avg latency, 20059.0 ms max latency.
16245 records sent, 3248.4 records/sec (3.17 MB/sec), 20686.8 ms avg latency, 21703.0 ms max latency.
3465 records sent, 691.6 records/sec (0.68 MB/sec), 23867.4 ms avg latency, 25930.0 ms max latency.
5070 records sent, 972.2 records/sec (0.95 MB/sec), 25666.6 ms avg latency, 26854.0 ms max latency.
2100 records sent, 405.8 records/sec (0.40 MB/sec), 25806.4 ms avg latency, 28076.0 ms max latency.
2655 records sent, 530.7 records/sec (0.52 MB/sec), 29127.3 ms avg latency, 29517.0 ms max latency.
12045 records sent, 2390.8 records/sec (2.33 MB/sec), 27875.3 ms avg latency, 29765.0 ms max latency.
4050 records sent, 810.0 records/sec (0.79 MB/sec), 29934.5 ms avg latency, 32629.0 ms max latency.
3465 records sent, 693.0 records/sec (0.68 MB/sec), 33464.6 ms avg latency, 34007.0 ms max latency.
3210 records sent, 637.8 records/sec (0.62 MB/sec), 34231.5 ms avg latency, 35004.0 ms max latency.
3150 records sent, 625.1 records/sec (0.61 MB/sec), 35804.0 ms avg latency, 36922.0 ms max latency.
2370 records sent, 471.5 records/sec (0.46 MB/sec), 36117.5 ms avg latency, 36974.0 ms max latency.
2115 records sent, 422.2 records/sec (0.41 MB/sec), 35739.5 ms avg latency, 36636.0 ms max latency.
4065 records sent, 805.9 records/sec (0.79 MB/sec), 37291.1 ms avg latency, 38202.0 ms max latency.
2970 records sent, 537.8 records/sec (0.53 MB/sec), 40304.6 ms avg latency, 43416.0 ms max latency.
2820 records sent, 556.7 records/sec (0.54 MB/sec), 46286.2 ms avg latency, 48648.0 ms max latency.
2220 records sent, 440.5 records/sec (0.43 MB/sec), 49961.4 ms avg latency, 52662.0 ms max latency.
1935 records sent, 383.2 records/sec (0.37 MB/sec), 54174.6 ms avg latency, 55922.0 ms max latency.
2685 records sent, 528.3 records/sec (0.52 MB/sec), 57413.6 ms avg latency, 58053.0 ms max latency.
1440 records sent, 267.5 records/sec (0.26 MB/sec), 59350.7 ms avg latency, 61014.0 ms max latency.
1200 records sent, 236.3 records/sec (0.23 MB/sec), 62711.7 ms avg latency, 64252.0 ms max latency.
1215 records sent, 215.9 records/sec (0.21 MB/sec), 66087.4 ms avg latency, 67900.0 ms max latency.
615 records sent, 121.3 records/sec (0.12 MB/sec), 69999.5 ms avg latency, 72387.0 ms max latency.
480 records sent, 88.6 records/sec (0.09 MB/sec), 74500.8 ms avg latency, 77430.0 ms max latency.
1890 records sent, 353.1 records/sec (0.34 MB/sec), 80205.1 ms avg latency, 81779.0 ms max latency.
1755 records sent, 348.6 records/sec (0.34 MB/sec), 82328.1 ms avg latency, 84487.0 ms max latency.
[2025-01-10 12:32:05,561] WARN [Producer clientId=perf-producer-client] Got error produce response with correlation id 33897 on topic-partition cpu0-0, retrying (2147483646 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2 (org.apache.kafka.clients.producer.internals.Sender)

```
`CPU 2개 총 전송시도 1,000,000 개 중 977,070 개 처리`

```
19350 records sent, 3866.9 records/sec (3.78 MB/sec), 7480.4 ms avg latency, 7642.0 ms max latency.
26790 records sent, 5358.0 records/sec (5.23 MB/sec), 7103.0 ms avg latency, 7637.0 ms max latency.
27630 records sent, 5524.9 records/sec (5.40 MB/sec), 5502.4 ms avg latency, 6265.0 ms max latency.
27615 records sent, 5523.0 records/sec (5.39 MB/sec), 5738.1 ms avg latency, 6059.0 ms max latency.
37005 records sent, 7396.6 records/sec (7.22 MB/sec), 4727.2 ms avg latency, 5558.0 ms max latency.
35565 records sent, 7110.2 records/sec (6.94 MB/sec), 4316.4 ms avg latency, 4449.0 ms max latency.
37995 records sent, 7599.0 records/sec (7.42 MB/sec), 4064.5 ms avg latency, 4300.0 ms max latency.
42345 records sent, 8469.0 records/sec (8.27 MB/sec), 3812.0 ms avg latency, 4064.0 ms max latency.
40980 records sent, 8196.0 records/sec (8.00 MB/sec), 3742.8 ms avg latency, 3880.0 ms max latency.
37410 records sent, 7482.0 records/sec (7.31 MB/sec), 3994.4 ms avg latency, 4290.0 ms max latency.
33150 records sent, 6630.0 records/sec (6.47 MB/sec), 4010.9 ms avg latency, 4714.0 ms max latency.
38190 records sent, 7631.9 records/sec (7.45 MB/sec), 4288.6 ms avg latency, 4859.0 ms max latency.
39840 records sent, 7966.4 records/sec (7.78 MB/sec), 4121.3 ms avg latency, 4354.0 ms max latency.
36420 records sent, 7284.0 records/sec (7.11 MB/sec), 4228.6 ms avg latency, 4372.0 ms max latency.
36525 records sent, 7296.2 records/sec (7.13 MB/sec), 4088.3 ms avg latency, 4354.0 ms max latency.
33270 records sent, 6652.7 records/sec (6.50 MB/sec), 4269.9 ms avg latency, 4706.0 ms max latency.
39300 records sent, 7860.0 records/sec (7.68 MB/sec), 4161.8 ms avg latency, 4720.0 ms max latency.
42300 records sent, 8460.0 records/sec (8.26 MB/sec), 3905.7 ms avg latency, 4230.0 ms max latency.
35265 records sent, 7053.0 records/sec (6.89 MB/sec), 4231.8 ms avg latency, 4515.0 ms max latency.
33285 records sent, 6657.0 records/sec (6.50 MB/sec), 4057.7 ms avg latency, 4718.0 ms max latency.
34380 records sent, 6818.7 records/sec (6.66 MB/sec), 4331.2 ms avg latency, 4780.0 ms max latency.
1035 records sent, 192.1 records/sec (0.19 MB/sec), 7021.2 ms avg latency, 10246.0 ms max latency.
555 records sent, 105.3 records/sec (0.10 MB/sec), 14459.5 ms avg latency, 17761.0 ms max latency.
585 records sent, 115.4 records/sec (0.11 MB/sec), 21077.1 ms avg latency, 23796.0 ms max latency.
735 records sent, 144.9 records/sec (0.14 MB/sec), 27500.0 ms avg latency, 29543.0 ms max latency.
795 records sent, 143.3 records/sec (0.14 MB/sec), 31249.0 ms avg latency, 35237.0 ms max latency.
345 records sent, 67.0 records/sec (0.07 MB/sec), 39254.5 ms avg latency, 42304.0 ms max latency.
555 records sent, 111.0 records/sec (0.11 MB/sec), 46450.9 ms avg latency, 48893.0 ms max latency.
765 records sent, 149.9 records/sec (0.15 MB/sec), 52880.5 ms avg latency, 54868.0 ms max latency.
750 records sent, 149.1 records/sec (0.15 MB/sec), 57552.1 ms avg latency, 59975.0 ms max latency.
1065 records sent, 184.9 records/sec (0.18 MB/sec), 61070.7 ms avg latency, 65631.0 ms max latency.
1365 records sent, 264.4 records/sec (0.26 MB/sec), 70711.8 ms avg latency, 73485.0 ms max latency.
495 records sent, 98.7 records/sec (0.10 MB/sec), 77627.6 ms avg latency, 80148.0 ms max latency.
585 records sent, 113.0 records/sec (0.11 MB/sec), 83200.5 ms avg latency, 85984.0 ms max latency.
765 records sent, 151.6 records/sec (0.15 MB/sec), 89244.2 ms avg latency, 92100.0 ms max latency.
120 records sent, 17.5 records/sec (0.02 MB/sec), 94314.5 ms avg latency, 99527.0 ms max latency.
180 records sent, 35.7 records/sec (0.03 MB/sec), 105727.9 ms avg latency, 108426.0 ms max latency.
435 records sent, 85.5 records/sec (0.08 MB/sec), 111736.6 ms avg latency, 113718.0 ms max latency.
945 records sent, 110.4 records/sec (0.11 MB/sec), 116716.8 ms avg latency, 123205.0 ms max latency.
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
1 records sent, 0.1 records/sec (0.00 MB/sec), 135454.0 ms avg latency, 135454.0 ms max latency.
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
3 records sent, 0.6 records/sec (0.00 MB/sec), 142606.3 ms avg latency, 142906.0 ms max latency.
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120040 ms has passed since batch creation
11 records sent, 2.0 records/sec (0.00 MB/sec), 151634.2 ms avg latency, 155202.0 ms max latency.
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120038 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120034 ms has passed since batch creation
16 records sent, 2.9 records/sec (0.00 MB/sec), 164032.1 ms avg latency, 167049.0 ms max latency.
org.apache.kafka.common.errors.TimeoutException: Expiring 15 record(s) for cpu0-0:120034 ms has passed since batch creation
```
- 34380개에서 1035개로 떨어지는 시점을 장애 상황으로 판단 `총 1,000,000개 중 750,510개 처리`

## 결과 비교
- 토픽 처리량이 많지 않은 상황이라면 오히려 싱글 코어 측 성능이 레이턴시 및 처리에 있어서 이점이 있음
- 멀티코어 이점으로 다중 처리에 강점이 있으나, ISR , zookeeper 및 네트워크 처리 속도가 저하되어 장애를 유발 할 수 있음
- CPU 처리 속도 < 네트워크 처리 속도 인 상황에서는 `TimeoutException` 으로 메세지가 유실 될 수 있음

---
### VM 부하 테스트
- 평시 상황에 producer 성능 테스트는 선행에서 진행하였음으로 제외
- VM 부하 시 성능확인

### VM 부하 시 기대 결과 값
- 메모리 버퍼에 쓰여진 토픽 유실
- 브로커 장애
- 오프셋 소실

### VM 부하 시나리오
- max.request.size 가 1048576 인 상황에서 지속적으로 해당 값에 90% 943718 사이즈를 전송
- 외부 서비스로 consume
- `kafka-producer-perf-test --producer-props bootstrap.servers=localhost:29092 --topic cpu1 --num-records 500 --throughput -1 --record-size 943718 --print-metric`
---

### Producer 설정
```java
@Configuration
public class KafkaProducerConfig {

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.ACKS_CONFIG, "all");
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```
### Consumer 설정
``` java
@Configuration
public class KafakConsumerConfig {

    @Bean
    public ConsumerFactory<String,String> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        return new DefaultKafkaConsumerFactory<String, String>(config);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
```
### Producder, Consumer 정상 동작 케이스
![crawler_service_0](https://github.com/user-attachments/assets/5df28fd9-da12-4f51-9d49-fdb04b4323dc)
---

### 브로커에 부하 발생 시
```
[root@kafka1 appuser]# kafka-producer-perf-test --producer-props bootstrap.servers=localhost:29092 --topic cpu1 --num-records 500 --throughput -1 --record-size 943718 --print-metric
1 records sent, 0.0 records/sec (0.01 MB/sec), 60134.0 ms avg latency, 60134.0 ms max latency.
org.apache.kafka.clients.producer.BufferExhaustedException: Failed to allocate 943805 bytes within the configured max blocking time 60000 ms. Total memory: 33554432 bytes. Available memory: 521257 bytes. Poolable size: 16384 bytes
1 records sent, 0.0 records/sec (0.02 MB/sec), 120840.0 ms avg latency, 120840.0 ms max latency.
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120002 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120004 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120002 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120001 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120003 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120002 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120005 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120012 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120003 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120003 ms has passed since batch creation
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for cpu1-0:120002 ms has passed since batch creation
```
![jvm_0](https://github.com/user-attachments/assets/770913d6-9544-4244-9e2c-50c851146f00)
- 레코드 사이즈가 클 시 EDEN 영역 메모리 사용량 증가

![jvm_1](https://github.com/user-attachments/assets/15267d30-9dfa-402c-82f8-96f6a615d3a6)
- Producer 측 타임 아웃에러가 나도 EDEN 영역 (힙 메모리 사용량이 지속적으로 증가함)
- Young 영역에 Garabage Collection 동작 이후 안정화가 된 모습


![crawler_service_1](https://github.com/user-attachments/assets/3d623abb-261b-4ac9-b326-7f79751893bc)

- Producer 정상 작동
- Consumer Response 에러

```
[Crawling_Service] [nio-8080-exec-8] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1736520658467
INFO 41585 --- [Crawling_Service] [nio-8080-exec-8] o.a.k.c.c.internals.LegacyKafkaConsumer  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Subscribed to topic(s): vmtest
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cluster ID: olNXbf6uTXiYmHm4aJ2NLw
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] (Re-)joining group
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Request joining group due to: need to re-join with the given member-id: consumer-default-group-id-2-1f3185ea-a0cc-4d93-a4cc-460a9d2fb076
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] (Re-)joining group
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Successfully joined group with generation Generation{generationId=7, memberId='consumer-default-group-id-2-1f3185ea-a0cc-4d93-a4cc-460a9d2fb076', protocol='range'}
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Finished assignment for group at generation 7: {consumer-default-group-id-2-1f3185ea-a0cc-4d93-a4cc-460a9d2fb076=Assignment(partitions=[vmtest-0])}
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Successfully synced group in generation Generation{generationId=7, memberId='consumer-default-group-id-2-1f3185ea-a0cc-4d93-a4cc-460a9d2fb076', protocol='range'}
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Notifying assignor about the new Assignment(partitions=[vmtest-0])
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Adding newly assigned partitions: vmtest-0
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : default-group-id: partitions assigned: [vmtest-0]
WARN 41585 --- [Crawling_Service] [nio-8080-exec-9] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.context.request.async.AsyncRequestTimeoutException]
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight HEARTBEAT request with correlation id 8 due to node 2147483646 being disconnected (elapsed time since creation: 31415ms, elapsed time since send: 31415ms, request timeout: 30000ms)
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight HEARTBEAT request with correlation id 9 due to node 2147483646 being disconnected (elapsed time since creation: 28415ms, elapsed time since send: 28415ms, request timeout: 30000ms)
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight HEARTBEAT request with correlation id 10 due to node 2147483646 being disconnected (elapsed time since creation: 25414ms, elapsed time since send: 25414ms, request timeout: 30000ms)
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight OFFSET_FETCH request with correlation id 11 due to node 2147483646 being disconnected (elapsed time since creation: 23012ms, elapsed time since send: 23012ms, request timeout: 30000ms)
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight HEARTBEAT request with correlation id 12 due to node 2147483646 being disconnected (elapsed time since creation: 18003ms, elapsed time since send: 18003ms, request timeout: 30000ms)
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight HEARTBEAT request with correlation id 13 due to node 2147483646 being disconnected (elapsed time since creation: 13002ms, elapsed time since send: 13002ms, request timeout: 30000ms)
INFO 41585 --- [Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight HEARTBEAT request with correlation id 14 due to node 2147483646 being disconnected (elapsed time since creation: 8002ms, elapsed time since send: 8002ms, request timeout: 30000ms)
[Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Cancelled in-flight HEARTBEAT request with correlation id 15 due to node 2147483646 being disconnected (elapsed time since creation: 3001ms, elapsed time since send: 3001ms, request timeout: 30000ms)
[Crawling_Service] [efault-group-id] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
[Crawling_Service] [anNameSet-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-default-group-id-2, groupId=default-group-id] Disconnecting from node 3 due to request timeout.
```
- 추가 문제점 
- 도커 프리즈
![docker_0](https://github.com/user-attachments/assets/19e7e2eb-aa28-4f31-bc41-d89bfbf62eaa)
![docker_1](https://github.com/user-attachments/assets/f1302f95-93d7-45f3-8430-19d3009676b9)
![docker_2](https://github.com/user-attachments/assets/4b6f2ee3-5ab9-4ab4-b10e-34d31c2ee009)

- docker process Kill 후 colima 재 시작
```
501 41996     1   0 11:51PM ??         0:00.01 /usr/bin/ssh -F /dev/null -o IdentityFile="/Users/sun/.colima/_lima/_config/user" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o NoHostAuthenticationForLocalhost=yes -o GSSAPIAuthentication=no -o PreferredAuthentications=publickey -o Compression=no -o BatchMode=yes -o IdentitiesOnly=yes -o Ciphers="^aes128-gcm@openssh.com,aes256-gcm@openssh.com" -o User=sun -o ControlMaster=auto -o ControlPath="/Users/sun/.colima/_lima/colima/ssh.sock" -o ControlPersist=yes -q -p 49192 127.0.0.1 -- cd /Users/sun || cd /Users/sun ; exec "$SHELL" --login -c 'docker ps -q'
```

### 결과 
- 브로커 설정에 의존 시 메세지 유실과 브로커 부하로 이어질 수 있음
- 메세지 송신 시 방어 로직을 구현하는게 서비스 안정성을 가져갈 수 있을 것으로 보인다.
