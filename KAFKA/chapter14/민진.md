# Chapter 14. 스트림 처리

## **14. 스트림 처리 개요 ☁️**

카프카는 원래 단순 메시지 버스로서 안정적인 이벤트 스트림 전달에 초점을 맞춤

### **카프카의 역사와 역할**

카프카를 기반으로 Apache Storm, Spark Streaming, Flink, Samza 등 다양한 스트림 처리 시스템이 개발됨

### **카프카 스트림즈의 등장**

버전 0.10.0부터 카프카는 자체 스트림 처리 라이브러리인 카프카 스트림즈를 제공하여 외부 프레임워크 없이도 이벤트 소비, 처리, 생산이 가능해짐

## **14.1 스트림 처리란 무엇인가? 🔍**

### **정의의 혼란**

- 스트림 처리에 대한 정의는 구현 세부 사항, 성능 요구사항, 데이터 모델 등이 혼합되어 혼란을 초래하는 경우가 많음
- 관계형 데이터베이스의 추상적 정의가 실제 구현과 한계에 얽매인 사례와 유사함
- 특정 구현의 제한이 스트림 처리의 본질을 결정하는 것은 아님

### **데이터 스트림의 기본 개념**

- **무한하고 계속 증가하는 데이터 집합**
    - 데이터 스트림은 시간이 지남에 따라 새로운 레코드가 계속 추가되는 무한한 이벤트 집합임
    - 신용카드 거래, 주식 거래, 배송 기록, 네트워크 이벤트 등 거의 모든 비즈니스 활동을 표현할 수 있음

### **데이터 스트림의 주요 속성**

- **순서 보장**
    - 이벤트는 발생 순서가 있으며, 그 순서에 따라 의미가 달라짐 (ex. 입금 후 출금 vs. 출금 후 입금)
- **불변성**
    - 발생한 이벤트는 수정되지 않고, 변경이 필요할 경우 새로운 이벤트가 추가됨
    - 데이터베이스 테이블과 달리, 이벤트는 삭제나 업데이트 없이 계속해서 축적됨
- **재생 가능성**
    - 과거의 이벤트 스트림을 재생할 수 있어, 오류 수정, 새로운 분석, 감사를 수행할 수 있음
    - 이 기능은 카프카가 스트림 처리에 강점을 가지는 주요 이유임

### **스트림 처리의 프로그래밍 패러다임**

- **지속적이고 비차단적 처리**
    - 이벤트 스트림을 지속적으로 읽고 처리하며 결과를 출력하는 연속적인 방식임
- **다른 처리 방식과의 비교**
    - **요청-응답:** 매우 낮은 지연(밀리초 단위)과 차단적 처리 (ex. OLTP)
    - **배치 처리:** 일정 시간마다 대량 데이터를 처리하여 높은 처리량을 제공하지만 지연이 큼 (ex. 데이터 웨어하우스, BI 시스템)
    - **스트림 처리:** 요청-응답과 배치 처리 사이에서, 실시간은 아니더라도 지속적이고 적시성 있는 처리를 제공

## 14.2 스트림 처리 개념 📚

### **14.2.1 토폴로지**

- 스트림 처리 애플리케이션은 하나 이상의 소스 스트림에서 시작해 여러 프로세서를 거쳐 결과를 출력하는 토폴로지(DAG)로 구성됨
- 각 프로세서는 필터, 카운트, 그룹바이, 조인 등의 연산을 수행하며, 이벤트가 단계별로 변환됨

### **14.2.2 시간**

- **중요성과 복잡성**
    - 스트림 처리에서는 공통된 시간 기준이 매우 중요하며, 주로 시간 창(window) 연산에 사용됨
- **시간 유형**
    - **이벤트 시간:** 이벤트가 실제 발생한 시간 (가장 중요한 기준)
    - **로그 추가 시간:** 카프카 브로커에 이벤트가 저장된 시간 (보조 기준)
    - **처리 시간:** 애플리케이션이 이벤트를 처리한 시간 (스레드나 인스턴스에 따라 달라 신뢰성이 낮음)
- **타임스탬프 처리**
    - 카프카 스트림즈는 `TimestampExtractor` 인터페이스를 통해 적절한 타임스탬프를 할당함
- **시간대 관리**
    - 전체 데이터 파이프라인은 단일 시간대 기준으로 운영되어야 하며, 필요 시 이벤트에 시간대 정보를 포함해야 함

### **14.2.3 상태**

- **단일 이벤트 처리**
    - 단일 이벤트 처리의 경우 별도의 상태 유지 없이 간단하게 처리 가능
- **여러 이벤트 집계**
    - 이동 평균, 카운트, 조인 등 여러 이벤트를 함께 처리하기 위해 상태(state)를 유지해야 함
- **상태 유형**
    - **로컬(내부) 상태:** 애플리케이션 인스턴스 내에서 관리되는 임베디드 인메모리 데이터베이스(RocksDB 등)를 사용하여 빠르게 접근
    - **외부 상태:** NoSQL 등 외부 저장소에 상태를 보관하여 다수 인스턴스에서 접근할 수 있으나, 추가 지연과 복잡성이 있음

### **14.2.4 스트림-테이블 이원성**

- 스트림은 이벤트 변화의 기록이며, 테이블은 누적된 현재 상태를 나타냄
- 테이블을 스트림으로 변환하려면 변경(삽입, 수정, 삭제) 이벤트를 캡처하고, 반대로 스트림을 테이블로 재구성(materialize)할 수 있음

### **14.2.5 시간 윈도우**

- 스트림 연산은 주로 시간 단위의 창을 기반으로 수행됨
- **창 크기:** 연산에 사용할 시간 범위 (ex. 5분, 15분, 하루 등)
- **이동 간격:** 창이 얼마나 자주 갱신되는지 (호핑 윈도우 vs. 텀블링 윈도우)
- **유예 기간:** 지연된 이벤트를 보정할 수 있는 기간을 설정하여 업데이트 가능
- 창은 시계 기준 정렬 또는 애플리케이션 시작 시점을 기준으로 구성할 수 있음

### **14.2.6 처리 보장**

- **정확히 한 번 처리**
    - 각 레코드를 정확히 한 번 처리하는 것이 핵심 요구사항임
    - 카프카 스트림즈는 트랜잭션과 멱등성 기능을 활용해 Exactly-Once Semantics를 보장함
- **타임스탬프 규칙**
    - 입력 레코드의 타임스탬프를 유지, 집계 결과에서는 최대 타임스탬프 사용, 조인 시 두 레코드 중 큰 값 선택 등 다양한 규칙을 적용함

## **14.3 스트림 처리 디자인 패턴 🎨**

### **14.3.1 단일 이벤트 처리**

- 각 이벤트를 개별적으로 처리하는 기본 패턴
- 이벤트 변환(맵)과 필터링을 통해 불필요한 데이터를 제거하거나 형식을 변환함
- 별도의 상태 유지 없이 독립적으로 처리할 수 있어 장애 복구와 로드 밸런싱에 유리함

### **14.3.2 로컬 상태와 스트림 처리**

- 이동 평균, 최소/최대 값 계산 등 이벤트 집계에 필요함
- 각 애플리케이션 인스턴스는 할당된 파티션의 데이터를 위해 로컬 상태를 유지함
- 메모리 사용량, 상태의 지속성, 파티션 재분배 등의 이슈를 고려해야 하며, 카프카 스트림즈는 내장 RocksDB와 카프카 토픽(로그 압축 활용)으로 이를 지원함

### **14.3.3 다단계 처리/리파티셔닝**

- 모든 데이터를 단일 인스턴스에서 집계하기 어려운 경우, 2단계 이상의 처리가 필요함
- 먼저 로컬 상태로 각 그룹(ex. 상위 10개 주식)을 집계한 후, 결과를 단일 파티션 토픽으로 전송하여 전체 집계를 수행함
- MapReduce의 여러 reduce 단계와 유사하지만, 대부분의 스트림 처리 프레임워크에서는 한 애플리케이션 내에서 처리할 수 있음

### **14.3.4 외부 검색을 사용하는 처리: 스트림-테이블 조인**

- 스트림 데이터를 외부 데이터(예: 사용자 프로필)와 결합하여 데이터를 풍부하게 만듦
- 직접 외부 조회 시 발생하는 지연과 부하를 줄이기 위해, CDC(Change Data Capture)를 통해 데이터베이스 변경을 이벤트로 받아 로컬 캐시를 갱신함
- 이를 통해 외부 데이터 소스를 거치지 않고 로컬 상태에서 빠르게 조회할 수 있음

### **14.3.5 테이블-테이블 조인**

- 두 개의 테이블(즉, 스트림을 재구성한 현재 상태)을 조인하여 최신 상태를 결합함
- 동일한 키와 파티셔닝을 전제로 하는 동등 조인(equi-join)을 통해 효율적인 분산 처리가 가능함
- 외래 키를 이용한 조인도 지원하여 보다 유연한 결합이 가능함

### **14.3.6 스트리밍 조인**

- 두 개의 실제 이벤트 스트림을 시간 창 내에서 조인하는 방식임
- 예를 들어, 검색 쿼리와 클릭 이벤트를 동일 시간 창 내에서 결합해 분석함
- 윈도우 조인(windowed join)을 통해 시간 기반 매칭을 수행함

### **14.3.7 비순차 이벤트**

- 이벤트 도착 순서가 어긋나는 경우를 감지하고, 일정 기간 내에 보정 처리함
- 이벤트 시간과 현재 처리 시간을 비교하여, 정의된 유예 기간 내에서는 결과를 업데이트할 수 있도록 함
- 지속적 처리 환경에서는 배치 작업과 달리, 실시간으로 오래된 이벤트를 반영할 수 있도록 설계해야 함

### **14.3.8 재처리하기**

- 애플리케이션 개선 후 기존 데이터 스트림에 대해 새로운 버전으로 결과를 생성하거나,
- 버그 수정 후 기존 결과를 재계산해야 하는 경우 적용함
- 새로운 컨슈머 그룹을 사용하거나 상태 리셋 도구를 활용하여 처리할 수 있으며, 첫 번째 방식이 안전하고 비교 분석에 유리함

### **14.3.9 인터랙티브 쿼리**

- 애플리케이션 내부 상태(ex. 테이블 형태)를 직접 쿼리하여 빠른 응답을 제공함
- 출력 토픽 대신 내장 상태 저장소를 활용해 최신 결과를 조회할 수 있도록 카프카 스트림즈가 API를 제공함

## **14.4 예제로 보는 카프카 스트림즈 💻**

### **14.4.1 단어 개수 세기**

**목적 및 개요**

- 입력 토픽(`"wordcount-input"`)에서 텍스트 데이터를 읽어 각 라인을 단어로 분리
- 단어를 키로 재할당한 후, 특정 단어(`"the"`)를 필터링
- `groupBy`와 카운트 연산을 통해 단어별 빈도를 계산한 후, 결과를 출력 토픽(`"wordcount-output"`)에 기록

**예제 코드**

```java
public class WordCountExample {
    public static void main(String[] args) throws Exception {
        // 카프카 스트림즈 설정
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "wordcount");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG,
                  Serdes.String().getClass().getName());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,
                  Serdes.String().getClass().getName());

        // 스트림 토폴로지 정의
        StreamsBuilder builder = new StreamsBuilder();
        KStream<String, String> source = builder.stream("wordcount-input");
        final Pattern pattern = Pattern.compile("\\W+");
        KStream<String, String> counts = source
            .flatMapValues(value -> Arrays.asList(pattern.split(value.toLowerCase())))
            .map((key, value) -> new KeyValue<>(value, value))
            .filter((key, value) -> (!value.equals("the")))
            .groupByKey()
            .count()
            .mapValues(value -> Long.toString(value))
            .toStream();
        counts.to("wordcount-output");

        // KafkaStreams 객체 생성 및 실행
        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();
        // 예제에서는 5초간 실행 후 종료
        Thread.sleep(5000L);
        streams.close();
    }
}
```

**설명**

- `StreamsBuilder`로 입력 토픽에서 데이터를 읽어 토폴로지를 생성함
- 정규식을 이용해 텍스트를 단어로 분리하고, 각 단어를 키로 재할당한 후 그룹화 및 카운트함
- 최종 결과는 출력 토픽에 기록되며, 동일한 코드를 로컬 환경이나 프로덕션 클러스터에서 실행 가능함

### **14.4.2 주식 시장 통계 예제**

**목적 및 개요**

- 주식 거래 이벤트(티커, ask 가격, ask 수량)를 입력 토픽(`"stocktrades-input"`)에서 읽어옴
- 티커별로 그룹화한 후, 5초 윈도우를 사용해 집계함
- 각 윈도우에서 최소 ask 가격, 거래 건수, 평균 ask 가격을 계산해 출력 토픽(`"stockstats-output"`)에 기록함

**설정 및 Serde 생성 (ex. Trade 객체용)**

```java
static public final class TradeSerde extends WrapperSerde<Trade> {
    public TradeSerde() {
        super(new JsonSerializer<Trade>(),
              new JsonDeserializer<Trade>(Trade.class));
    }
}
```

**예제 코드**

```java
// 카프카 스트림즈 설정
Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "stockstat");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, Constants.BROKER);
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG,
          Serdes.String().getClass().getName());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,
          TradeSerde.class.getName());

// 토폴로지 정의
StreamsBuilder builder = new StreamsBuilder();
KStream<String, Trade> source = builder.stream("stocktrades-input");

// 윈도우 사이즈 (5000밀리초 예시)
long windowSize = 5000L;
KStream<Windowed<String>, TradeStats> stats = source
    .groupByKey() // 동일 티커 그룹핑
    .windowedBy(TimeWindows.of(Duration.ofMillis(windowSize))
        .advanceBy(Duration.ofSeconds(1)))
    .aggregate(
        () -> new TradeStats(),
        (k, v, tradeStats) -> tradeStats.add(v),
        Materialized.<String, TradeStats, WindowStore<Bytes, byte[]>>as("trade-aggregates")
            .withValueSerde(new TradeStatsSerde())
    )
    .toStream()
    .mapValues(tradeStats -> tradeStats.computeAvgPrice());

// 결과 출력: 윈도우 정보 포함하여 출력 토픽에 기록
stats.to("stockstats-output",
         Produced.keySerde(WindowedSerdes.timeWindowedSerdeFrom(String.class, windowSize)));

// KafkaStreams 객체 생성 및 실행
KafkaStreams streams = new KafkaStreams(builder.build(), props);
streams.start();
Thread.sleep(10000L);
streams.close();
```

**설명**

- 입력 토픽에서 주식 거래 데이터를 읽어 티커별로 그룹화함
- 5초 길이의 윈도우를 매초 갱신하며 `TradeStats` 객체로 집계를 수행함
- 집계 결과를 통해 평균 가격 등을 계산한 후 출력 토픽에 기록함

### **14.4.3 클릭 스트림 확장**

**목적 및 개요**

- 웹 클릭 이벤트, 검색 이벤트, 사용자 프로필 업데이트 스트림을 활용하여 사용자 활동을 풍부하게 분석함
- 클릭 이벤트와 사용자 프로필(`KTable`)을 좌측 조인해 사용자 정보를 추가함
- 풍부화된 클릭 이벤트와 검색 이벤트를 1초 시간 창 내에서 `left-join`하여 결합함
- 최종 결과를 출력 토픽(`"useractivity-output"`)에 기록함

**예제 코드**

```java
// 스트림 및 테이블 생성
KStream<Integer, PageView> views = builder.stream(
    Constants.PAGE_VIEW_TOPIC,
    Consumed.with(Serdes.Integer(), new PageViewSerde())
);

KStream<Integer, Search> searches = builder.stream(
    Constants.SEARCH_TOPIC,
    Consumed.with(Serdes.Integer(), new SearchSerde())
);

KTable<Integer, UserProfile> profiles = builder.table(
    Constants.USER_PROFILE_TOPIC,
    Consumed.with(Serdes.Integer(), new ProfileSerde())
);

// 스트림-테이블 조인: 클릭 이벤트와 사용자 프로필을 좌측 조인하여 풍부화
KStream<Integer, UserActivity> viewsWithProfile = views.leftJoin(
    profiles,
    (page, profile) -> {
        if (profile != null)
            return new UserActivity(
                profile.getUserID(), profile.getUserName(),
                profile.getZipcode(), profile.getInterests(),
                "", page.getPage());
        else
            return new UserActivity(
                -1, "", "", null, "", page.getPage());
    }
);

// 스트림-스트림 조인: 풍부화된 클릭 이벤트와 검색 이벤트를 1초 시간 창 내에서 좌측 조인
KStream<Integer, UserActivity> userActivityKStream = viewsWithProfile.leftJoin(
    searches,
    (userActivity, search) -> {
        if (search != null)
            userActivity.updateSearch(search.getSearchTerms());
        else
            userActivity.updateSearch("");
        return userActivity;
    },
    JoinWindows.of(Duration.ofSeconds(1)).before(Duration.ofSeconds(0)),
    StreamJoined.with(Serdes.Integer(), new UserActivitySerde(), new SearchSerde())
);

// 결과 출력
userActivityKStream.to("useractivity-output", Produced.with(Serdes.Integer(), new UserActivitySerde()));

// KafkaStreams 객체 생성 및 실행
KafkaStreams streams = new KafkaStreams(builder.build(), props);
streams.start();
Thread.sleep(10000L);
streams.close();
```

**설명**

- 클릭 이벤트와 검색 이벤트 스트림, 그리고 사용자 프로필 테이블을 생성함
- 스트림-테이블 조인을 통해 클릭 이벤트에 사용자 정보를 추가하고,
- 이어서 `left-join`을 통해 검색 이벤트와 결합하여, 관련 이벤트를 1초 시간 창 내에서 매칭함
- 최종 사용자 활동 데이터는 출력 토픽에 기록되며, 분석 및 추천 등 다양한 용도로 활용 가능함

## **14.5 카프카 스트림즈: 아키텍처 개요 🏗️**

### **14.5.1 토폴로지 구축**

- 모든 스트림 애플리케이션은 입력에서 출력까지 이벤트가 흐르는 하나의 토폴로지(DAG)로 구성됨
- 소스 프로세서(토픽에서 데이터 수신), 변환 프로세서(필터, 맵, 집계 등), 싱크 프로세서(결과 내보내기)로 구성

### **14.5.2 토폴로지 최적화하기**

- `StreamsBuilder.build()` 단계에서 논리적 토폴로지를 물리적 토폴로지로 변환하며 최적화 적용
- `StreamsConfig.TOPOLOGY_OPTIMIZATION` 옵션을 통해 불필요한 토픽 재사용 등 최적화 가능

### **14.5.3 토폴로지 테스트하기**

- `TopologyTestDriver`를 사용해 단위 테스트 진행
- `EmbeddedKafkaCluster`나 `Testcontainers`를 활용해 통합 테스트 수행

### **14.5.4 토폴로지 규모 확장하기**

- 한 인스턴스 내에서 여러 스레드를 실행하거나 여러 서버에 분산 실행 가능
- 토폴로지는 입력 토픽 파티션 수에 따라 태스크로 분할되어 병렬 처리됨
- 조인이나 재분배가 필요한 경우, 관련 파티션을 동일 태스크에 할당해 처리

### **14.5.5 장애 처리하기**

- 카프카에 저장된 데이터와 변경 로그를 활용해 장애 발생 시 마지막 오프셋부터 재시작
- 소비자 그룹 코디네이션과 협력적 리밸런싱을 통해 실패한 태스크가 다른 스레드나 인스턴스로 재할당됨
- 내부 토픽의 적극적 압축 및 스탠바이(replica) 설정으로 상태 복구 시간 단축 가능

## **14.6 스트림 처리 활용 사례 💡**

### 고객 서비스 개선

- **내용:** 예약 후, 이메일, 고객 서비스, 호텔 프론트 등 여러 시스템이 실시간으로 업데이트되어 예약 확인, 영수증 발송, 고객 정보 조회 등을 즉시 수행할 수 있도록 함
- **효과:** 고객은 몇 분 내에 확인 이메일을 받으며, 신속한 응대를 통해 만족도가 향상됨

### 사물인터넷(IoT) 예방 정비

- **내용:** 센서와 장치에서 발생하는 대규모 이벤트를 실시간으로 처리하여, 기계의 이상 징후나 예방 정비가 필요한 시점을 예측함
- **적용 분야:** 제조업, 통신(ex. 결함 있는 기지국), 케이블 TV(ex. 이상 있는 셋톱박스) 등
- **효과:** 장치 고장 전 사전 대응으로 비용 절감 및 서비스 안정성을 향상시킴

### 부정 행위 감지

- **내용:** 신용카드, 주식 거래, 게임 내 부정 행위, 사이버 보안 등에서 대규모 이벤트 스트림을 분석하여 이상 패턴을 빠르게 탐지함
- **특징:** 이상 징후를 실시간으로 포착해 부정 행위를 미연에 방지할 수 있도록 함
- **예시:** 사이버 보안 분야에서는 비정상적인 외부 통신(비콘 신호 등)을 실시간으로 감지해 조기 경고를 제공함

## **14.7 스트림 처리 프레임워크 선택하기 🔧**

### **애플리케이션 유형에 따른 고려사항**

- **데이터 수집**
    - 하나의 시스템에서 다른 시스템으로 데이터를 전달하며, 필요한 경우 데이터 형식을 변환
    - 단순 인제스트 시스템(Kafka Connect)도 고려할 수 있음
- **밀리초 단위 작업**
    - 거의 즉각적인 응답이 필요한 애플리케이션 (ex. 일부 부정행위 감지)
    - 요청-응답 패턴이 더 적합할 수 있음
    - 스트림 처리 시스템 선택 시 이벤트 단위의 저지연 모델을 지원하는지 확인
- **비동기 마이크로서비스**
    - 대규모 비즈니스 프로세스의 일부로서 단순 작업(ex. 재고 변경)을 수행
    - 메시지 버스와 원활하게 통합되고, 변경 데이터 캡처(CDC) 기능 및 로컬 상태 저장 지원이 필수
- **준 실시간 데이터 분석**
    - 복잡한 집계, 윈도우, 조인 등을 통해 비즈니스에 유의미한 인사이트를 제공
    - 고급 집계, 다양한 윈도우 연산, 여러 종류의 조인 기능을 갖춘 API가 필요

### **보편적으로 고려해야 할 사항**

- **시스템 운용성**
    - 생산 배포, 모니터링, 문제 해결, 스케일 조정 등이 용이해야 함
    - 재처리(리프로세싱) 시 오류 복구 및 데이터 정합성 관리가 중요한지 확인
- **사용 및 디버깅 용이성**
    - 개발 및 배포 시간 단축을 위해 사용하기 쉬운 API와 깨끗한 추상화를 제공하는지 평가
    - 디버깅과 유지보수가 효율적으로 이루어질 수 있어야 함
- **어려운 일을 쉽게 해줌**
    - 고급 기능(윈도우 집계, 로컬 스토어 관리 등)을 쉽게 구현할 수 있도록 시스템이 복잡한 세부 사항을 내부적으로 처리하는지 검토
- **커뮤니티**
    - 활발한 오픈 소스 커뮤니티가 존재하는지 확인
    - 최신 기능 업데이트, 버그 수정, 사용자 지원 및 문서화 수준 등을 고려
