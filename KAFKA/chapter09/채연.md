# 09. 카프카 커넥터
### 데이터 파이프 라인에 있어서의 카프카의 역할

- 데이터 파이프라인의 다양한 단계 사이의 매우 크고 안정적인 버퍼 역할
- 데이터 파이프라인의 데이터를 쓰는 쪽과 읽는 쪽을 분리
- 신뢰성, 보안성, 효율성으로 카프카가 데이터 파이프라인에 적합함

## 데이터 파이프라인 구축 시 고려사항

1. 적시성
    - 쓰는 쪽은 필요에 따라 자주 혹은 가끔 카프카에 실시간으로 쓸 수 있음
    - 읽는 쪽은 최신 이벤트가 도착하는 즉시 혹은 배치 형태로 데이터를 읽을 수 있음
    - 카프카를 쓰는 쪽과 읽는 쪽 사이의 시간적 민감도에 대한 요구 조건을 분리시키는 거대한 버퍼로 생각 
    → 백프레셔 적용
2. 신뢰성
    - 카프카는 자체적으로 최소 한 번 보장, 정확히 한 번 전달도 보장하므로 데이터 파이프라인 구축에 적합함
3. 높으면서도 조정 가능한 처리율
    - 카프는 쓰는 쪽과 읽는 쪽에서 버퍼 역할을 하므로 프로듀서 처리율과 컨슈머의 처리율을 묶어서 생각하지 않아도 됨
    - 카프카 자체적으로 높은 처리율을 받아낼 수 있는 분산 시스템
    - 카프카 커넥트 API는 작업을 병렬화 하는데 초점을 맞춤, 카프카의 압축 코덱으로 처리율이 높음
4. 데이터 형식
    - 카프카 자체와 카프카 커넥트 API는 데이터 형식에 완전히 독립적
    - 카프카 커넥트에서 장착 가능(pluggable)한 컨버터를 지원
5. 변환
    - 카프카 커넥트는 원본 시스템의 데이터를 카프카로 옮길 때 또는그 반대일 때 단위 레코드를 변환할 수 있게 해주는 단일 메시지 변환 기능이 있다.
    - ETL, ELT
        - ELT: 데이터 파이프라인은 대상 시스템에 전달되는 데이터가 원본 데이터와 최대한 비슷하도록 최소한의 변환만을 수행함 → 대상 시스템 사용자에게 최대한의 유연성을 제공해 줄 수 있음
    - Extract: 추출, Load: 적재, Transform: 변환
6. 보안
    - 카프카는 소스에서 카프카로 데이터를 보내거나 아니면 카프카에서 싱크로 데이터를 보내는 데이터 전송 과정에서 데이터 암호화를 지원
    - SASL을 사용한 인증과 인가 역시 지원
7. 장애 처리
    - 카프카는 장애가 발생해도 모든 이벤트를 장기간에 걸쳐 저장하도록 카프카를 설정할 수 있기 때문에, 필요할 경우 에러 복구 가능
8. 결합과 민첩성
    - 데이터 파이프라인과 데이터 원본과의 결합이 생기는 경우
        - Ad-hoc 파이프라인
            - ex) 로그스태시 - 엘라스틱서치, 플룸 - HDFS, 골든 게이트 - 오라클 등..
            - 새로운 시스템을 도입할 때마다 추가적인 데이터 파이프라인을 구축해야함
        - 메타데이터 유실
            - 데이터 파이프라인에서 스키마 진화를 지원한다면, 각 팀은 시스템 중단을 걱정할 필요 없이 자신들의 애플리케이션을 변경할 수 있음
        - 과도한 처리
            - 데이터를 최대한 가공되지 않은 로우데이터로 애플리케이션에 내려보내고, 데이터를 처리하고 집적하는 방법은 애플리케이션이 알아서 결정하게 하는 것이 좀 더 유연한 방법이다.

## 카프카 커넥트 vs 프로듀서/컨슈머

- 카프카 클라이언트: 애플리케이션의 코드를 변경할 수 있으면서 카프카에 데이터를 쓰거나 읽어오고 싶을 때 사용
- 카프카 커넥트: 카프카를 직접 코드나 API를 작성하지 않았고, 변경도 할 수 없는 데이터 저장소에 연결시켜야 할 때 사용 → 카프카 커넥트의 사용자들은 설정 파일만 작성하면 됨

## 카프카 커넥트

카프카 커넥터는 아파치 카프카의 일부로서, 카프카와 다른 데이터 저장소 사이에 확장성과 신뢰성을 가지면서 데이터를 주고받을 수 있는 수단을 제공함

- CDC(Change Data Capture)
- Debezium: 로그기반 CDC, 데이터베이스의 트랜잭션 로그를 모니터링하여 변경 사항 캡쳐 -> 소스 데이터베이스에 부하를 최소화하면서 실시간에 가까운 데이터 동기화 구현
- 실무사용사례: RDB → 카프카 커넥트 → app → ElasticSearch
- ETL vs ELT
  - ETL(Extract -> Transform -> Load): 정제된 데이터가 적재됨, 변환 가능에서 데이터 손실 가능성 있음
  - ELT(Extract -> Load -> Transform): 원본 데이터를 그대로 저장하므로 유연성이 높음
