## Chater 9. 데이터 파이프라인 구축하기

### 개요

* 데이터 파이프라인에서 안정적인 버퍼 역할을 수행
* 발행 구독을 분리함으로써 동일한 원본에 **적시성** 과 **가용성** 요구조건을 중촉

---
### **9.1 데이터 파이프라인 구축 시 고려사항**
**9.1.1 적시성(timeliness)**
- 적시성(timeliness)란
    - 필요한 시점에 정확히 전달되는 속성
- 적시성 주요개념
    1. 지연시간(Latency)
    2. 시간적 민감도 (Temporal Sensitivity)
- 카프카에서 적시성을 보장하는 방식
    - 시간적 민감도에 요구 조건을 분리 시킬 수 있음
    - Producer
        - `linger.ms=0` 메세지 즉시 처리
        - `linger.ms>0` 메세지 배치 단위로 처리
    - Consumer
        - `max.poll.insterval.ms` 메서지 소비 주기 조정
- 트래픽이 예상치 못하게 증가 했을 때, Consumer 측 소비 주기를 일일히 조정하기보단 Producer 측 처리 단위를 조정하여 백프레셔를 적용하는 방식도 가능
---
**9.1.2 신뢰성(Reliability)**
- 카프카에서 **전달보장(delivery guarantee)** 하는 방식
    - 카프카 자체적으로는 `최소 한 번` 을 보장함
    - 외부 저장소와 결합된 시스템에선 `정확히 한 번` 도 보장이 가능
    - 카프카 커넥트 API 가 외부 통합 지원 API를 제공함으로써 정확히 한 번을 구현하기 용이해짐
---
**9.1.3 높으면서도 조정 가능한 처리율**
- 카프카는 발행자 구독자 사이에서 버퍼 역할을 함
- 트래픽이 증가 했을 때, 컨슈머가 소비를 따라잡을 때 까지 카프카 내부에서 데이터가 누적만 되고 말 것
    - 이는 프로듀서 측 메세지 처리와 관계없이 컨슈머 측 가용 처리율을 보장
    - 카프카가 프로듀서 측 메세지를 장애없이 처리 할 수 있다면 큰 문제는 되지 않음
    - 적시성을 보장한다고하면 요구 조건에 맞춰 프로듀서, 컨슈머를 동적으로 확장 할 수 있음
---
**9.1.4 데이터 형식**
- 카프카와 커넥트 API 는 독립적이고 형식만 지원할 수 있으면 어떤 시리얼라이저도 쓸 수 있음
- 컨버터를 지원하며 커넥터는 영향을 받지 않음
- 카프카 데이터를 외부 저장소에 쓸 경우, **싱크 커넥터(sink connector)** 가 책임
---
**9.1.5 변환**
- 카프카에서 ETL 을 구현하는 방식
    - 카프카는 **단일 메세지변환(Single Message Transformation)** 기능을 탑재하여 간단한 형변환, 필터링, 필드 삭제를 지원함
    - 조인, 집계와 같은 경우는 Stand Alone 으로는 불가하며, Streams 나 KSQL을 활용해야함
---
**9.1.6 보안**
- 카프카는 I/O 과정에서 SASL 인증을 지원함
- 감사 로그를 지원하며 접근, 토픽 수정 내역이 추적이 가능함
---
**9.1.7 장애처리**
- **Retension** 설정을 통해 카프카는 장기간 메세지를 저장 할 수 있음
    - 시간 기준 `log.retention.ms`
    - 용량 기준 `log.retention.bytes` 
- 이를 통해 외부 시스템에 데이터가 유실되어도 복구가 가능함
---
**9.1.8 결합(Coupling)과 민첩성(Agility)**
- 임기응변(Ad-hoc) 파이프라인
    - 기존 ETL 방식에서는 ETL 툴, 형식, DB 간 호환에 따라 각 개 다른 방식으로 구축을 했어야만 했음
    - 별개 엔드포인트마다 파이프라인을 구축하기엔 비용과 시간이 너무 많이 소요
    
- 메타데이터 유실
    - 카프카에선 발행자와 카프카 사이에 느슨한 결합을 통해 외부 시스템 간 유연한 처리 가능
    ``` 
    예를 들어 스키마 메타데이터를 관리하지 상황에 전통적인 ETL 시스템에선 
    발행자-파이프라인-DataBase-어플리케이션 각 포인트 별로 스키마 정보를 업데이트 해줘야 한다면
    카프카를 통한 ETL 시스템에선 파이프라인에 갱신은 회피 할 수 있다는 점이다.
    ```
- 과도한 처리
    ```
    유지보수의 관점에서 데이터 파이프라인에서 많은 변환이 일어나게 된다면 커플링된 상태로 볼 수 있고 이는 명세가 바뀔 때 마다 변경 포인트가 많다는 단점을 가지고 있다.
    카프카에선 최소한의 변환만 주어 디커플링된 아키텍쳐를 구성하고 각 시스템별로 명세에 맞춰 변환하는게 유지보수 측면에서 효과적이다.
    ```
---
**9.2 카프카 커넥트 vs 프로듀서/컨슈머**

- 카프카 커넥트란
    - 외부 데이터 저장소의 데이터를 가져오거나, 쓸 때 사용
    - 커넥트 API 쪽이 설정 관리를 하는 것이 느슨한 결합에 용이

**9.3 카프카 커넥트**

- `bootstrap.servers`
    - 카프카 커넥트와 함꼐 동작하는 브로커 목록 브로커가 중계 역할을 함
- `group.id`
    - 동일한 그룹ID로 커넥트 클러스터를 구성함
- `plugin.path`
    - 플로그인 관리를 위한 환경변수의 역할
    - plugin.path 에 의존성을 바로 저장은 불가능
    - 카프카 커넥트의 클래스패스에 의존성을 추가 할 수 있지만 에러를 유발 할 수 있음
- `key.converter, value.converter`
    - 카프카에 저장될 메세지 키:밸류에 각각 컨버터를 지정할 수 있음
    - 키 `key.converter.schemas.enable = {true|false}`
    - 밸류 `value.converter.schemas.enable = {true|false}`
- `rest.host.name, rest.port`
    - 커넥터 설정엔 REST API를 사용하는 것이 보통
    - REST API 에 사용할 지정 옵션

---
**이하 환경구축 후 추가 예정**

---
**9.3.5 카프카 커넥트: 좀 더 자세히 알아보기**
- 커넥터
    - 태스크 실행 리소스 판단
    - 데이터 복사 작업을 분할하는 역할
    - 태스크 설정을 전달하는 역할
- 태스크 
    - 데이터를 실제로 넣거나 가져오는 역할을 수행
    - 태스크는 컨택스트를 받아서 초기화
    - 커넥터의 컨텍스트에는 레코드 제어 메서드가 존재 
    - 제어 메서드를 통해 `정확히 한 번`을 위한 오프셋 저장 혹은 백프레셔를 적용 하기 위해 사용됨
- 워커
    - 컨테이너 프로세스
    - RESTAPI, 설정 관리, 고가용성, 부하 분산을 담당
